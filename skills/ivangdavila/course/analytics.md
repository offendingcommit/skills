# Course Analytics & Improvement

## Key Metrics to Track

### Enrollment metrics
| Metric | Target | What it tells you |
|--------|--------|-------------------|
| Conversion rate | 2-5% | Sales page effectiveness |
| Refund rate | <10% | Product-market fit |
| Cost per acquisition | Varies | Marketing efficiency |
| Revenue per student | -- | Pricing optimization |

### Engagement metrics
| Metric | Target | What it tells you |
|--------|--------|-------------------|
| Completion rate | 30-50%+ | Course quality and design |
| Module drop-off | Identify spikes | Where students get stuck |
| Time to first lesson | <24h | Onboarding effectiveness |
| Avg session length | 15-30 min | Content consumption patterns |

### Quality metrics
| Metric | Target | What it tells you |
|--------|--------|-------------------|
| NPS score | >50 | Student satisfaction |
| Assessment pass rate | 70-85% | Content difficulty calibration |
| Support ticket volume | Decreasing | FAQ/content clarity |
| Testimonial rate | -- | Value delivery |


## Identifying Problem Areas

**High drop-off at specific lesson:**
- Is it too long? → Split into parts
- Is it too hard? → Add more examples
- Is it unclear? → Rerecord/rewrite
- Is it boring? → Add visuals, stories
- Is prerequisite missing? → Add bridging content

**Low assessment scores on specific topic:**
- Is the teaching unclear? → Improve explanation
- Are questions confusing? → Rewrite questions
- Is more practice needed? → Add exercises
- Is it too advanced? → Adjust difficulty curve

**High refund rate:**
- Mismatched expectations → Improve sales page clarity
- Poor first impression → Strengthen Module 1
- Technical issues → Fix platform/playback
- Wrong audience → Adjust targeting


## Feedback Collection

### Automated surveys
| When | Survey | Questions |
|------|--------|-----------|
| After Module 1 | Quick pulse | "How's it going so far?" (1-5) |
| Mid-course | Progress check | What's working? What's confusing? |
| Post-completion | Full NPS | Would you recommend? What would improve? |
| 30 days after | Outcomes | Have you applied what you learned? Results? |

### Qualitative feedback sources
- Community discussions (recurring themes)
- Support tickets (common questions)
- Direct replies to emails
- Testimonials and case studies
- Exit surveys (for refund requests)


## Improvement Prioritization

**Framework for what to fix first:**

| Impact | Effort | Priority |
|--------|--------|----------|
| High (affects completion) | Low | Fix immediately |
| High | High | Plan for next major update |
| Low | Low | Quick win, do when convenient |
| Low | High | Don't bother |

**Common high-impact improvements:**
1. Rerecord confusing lessons (high drop-off)
2. Add more examples to abstract concepts
3. Shorten overly long lessons
4. Improve Module 1 (sets expectations)
5. Add exercises where students struggle


## Reporting

### Weekly report (automated)
- New enrollments
- Revenue this week
- Active students
- Support tickets opened/closed
- Notable feedback

### Monthly analysis
- Completion funnel analysis
- Module-by-module engagement
- Assessment performance summary
- Feedback themes and patterns
- Improvement priorities for next month

### Quarterly review
- Overall course health (enrollment, completion, NPS)
- ROI on marketing spend
- Content update needs
- Pricing review
- Strategic adjustments (new modules, upsells, etc.)


## Iteration Workflow

**When data suggests a problem:**
1. Quantify: How many students affected? Where exactly?
2. Diagnose: Review the content, gather specific feedback
3. Hypothesize: What change would fix it?
4. Implement: Make the smallest change that could work
5. Measure: Did it improve the metric?
6. Document: What worked, what didn't, for future reference
