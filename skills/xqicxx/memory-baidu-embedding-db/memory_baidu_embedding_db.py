"""
ç™¾åº¦Embeddingå†…å­˜æ•°æ®åº“ - å¢å¼ºç‰ˆ
ç”¨äºæ›¿ä»£memory-lancedbçš„å‘é‡å†…å­˜ç³»ç»Ÿ
åŒ…å«å¢å¼ºçš„é”™è¯¯å¤„ç†ã€ç¼“å­˜æœºåˆ¶å’Œé™çº§åŠŸèƒ½
"""

import json
import os
import sqlite3
import hashlib
import traceback
from datetime import datetime
from typing import List, Dict, Optional, Tuple
from pathlib import Path
import threading
from functools import wraps

# å¯¼å…¥ç™¾åº¦Embeddingå®¢æˆ·ç«¯
import sys
sys.path.append('/root/clawd/skills/baidu-vector-db/')
from baidu_embedding_bce_v3 import BaiduEmbeddingBCEV3


def with_fallback(fallback_func=None):
    """è£…é¥°å™¨ï¼šå½“ä¸»è¦åŠŸèƒ½å¤±è´¥æ—¶è°ƒç”¨é™çº§å‡½æ•°"""
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            try:
                return func(*args, **kwargs)
            except Exception as e:
                if fallback_func:
                    print(f"âš ï¸  ä¸»åŠŸèƒ½å¤±è´¥ï¼Œä½¿ç”¨é™çº§åŠŸèƒ½: {str(e)}")
                    return fallback_func(*args, **kwargs)
                else:
                    raise
        return wrapper
    return decorator


class EnhancedMemoryBaiduEmbeddingDB:
    """
    å¢å¼ºç‰ˆåŸºäºç™¾åº¦Embeddingçš„å†…å­˜æ•°æ®åº“
    åŒ…å«é”™è¯¯å¤„ç†ã€ç¼“å­˜æœºåˆ¶å’Œé™çº§åŠŸèƒ½
    """
    
    def __init__(self, db_path: str = None, cache_size: int = 1000):
        """
        åˆå§‹åŒ–å†…å­˜æ•°æ®åº“
        
        Args:
            db_path: SQLiteæ•°æ®åº“è·¯å¾„
            cache_size: ç¼“å­˜å¤§å°
        """
        # ä»ç¯å¢ƒå˜é‡æˆ–é…ç½®æ–‡ä»¶åŠ è½½APIå‡­æ®
        api_string = os.getenv("BAIDU_API_STRING")
        secret_key = os.getenv("BAIDU_SECRET_KEY")
        
        # æ£€æŸ¥APIå‡­æ®æ˜¯å¦å­˜åœ¨
        if not api_string or not secret_key:
            print("âš ï¸  è­¦å‘Š: ç¼ºå°‘ç™¾åº¦APIå‡­æ®ï¼Œå°†ä½¿ç”¨é™çº§æ¨¡å¼!")
            print("   è¯·è®¾ç½®ä»¥ä¸‹ç¯å¢ƒå˜é‡ä»¥å¯ç”¨å®Œæ•´åŠŸèƒ½:")
            print("   export BAIDU_API_STRING='your_bce_v3_api_string'")
            print("   export BAIDU_SECRET_KEY='your_secret_key'")
            self.client = None
        else:
            try:
                self.client = BaiduEmbeddingBCEV3(api_string, secret_key)
            except Exception as e:
                print(f"âš ï¸  ç™¾åº¦APIå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {str(e)}ï¼Œä½¿ç”¨é™çº§æ¨¡å¼")
                self.client = None
        
        # è®¾ç½®æ•°æ®åº“è·¯å¾„
        self.db_path = db_path or os.path.join(os.path.expanduser("~"), ".clawd", "enhanced_memory_baidu.db")
        Path(self.db_path).parent.mkdir(parents=True, exist_ok=True)
        
        # åˆå§‹åŒ–æ•°æ®åº“
        self._init_db()
        
        # åˆå§‹åŒ–ç¼“å­˜
        self.cache_size = cache_size
        self.embedding_cache = {}
        self.cache_lock = threading.Lock()
        
        # é™çº§æ¨¡å¼æ ‡å¿—
        self.fallback_mode = self.client is None
    
    def _init_db(self):
        """
        åˆå§‹åŒ–SQLiteæ•°æ®åº“
        """
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # åˆ›å»ºè®°å¿†è¡¨
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS memories (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    content TEXT NOT NULL,
                    embedding_json TEXT,
                    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
                    tags TEXT,
                    metadata_json TEXT,
                    content_hash TEXT UNIQUE
                )
            ''')
            
            # åˆ›å»ºç´¢å¼•
            cursor.execute('CREATE INDEX IF NOT EXISTS idx_timestamp ON memories(timestamp)')
            cursor.execute('CREATE INDEX IF NOT EXISTS idx_tags ON memories(tags)')
            cursor.execute('CREATE INDEX IF NOT EXISTS idx_content_hash ON memories(content_hash)')
            
            conn.commit()
            conn.close()
        except sqlite3.Error as e:
            print(f"âŒ æ•°æ®åº“åˆå§‹åŒ–é”™è¯¯: {str(e)}")
            print(f"   è¯·æ£€æŸ¥æ•°æ®åº“è·¯å¾„æ˜¯å¦æœ‰æ•ˆ: {self.db_path}")
            print("   å¯èƒ½çš„åŸå› : æƒé™ä¸è¶³ã€ç£ç›˜ç©ºé—´ä¸è¶³æˆ–è·¯å¾„ä¸å­˜åœ¨")
            raise
        except Exception as e:
            print(f"âŒ åˆå§‹åŒ–æ•°æ®åº“æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {str(e)}")
            print("   è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
            traceback.print_exc()
            raise
    
    def _get_content_hash(self, content: str) -> str:
        """ç”Ÿæˆå†…å®¹å“ˆå¸Œç”¨äºå»é‡"""
        return hashlib.md5(content.encode()).hexdigest()
    
    def _add_to_cache(self, content: str, embedding: List[float]):
        """æ·»åŠ åˆ°åµŒå…¥ç¼“å­˜"""
        with self.cache_lock:
            if len(self.embedding_cache) >= self.cache_size:
                # ç§»é™¤æœ€è€çš„æ¡ç›®
                oldest_key = next(iter(self.embedding_cache))
                del self.embedding_cache[oldest_key]
            self.embedding_cache[content] = embedding
    
    def _get_from_cache(self, content: str) -> Optional[List[float]]:
        """ä»åµŒå…¥ç¼“å­˜è·å–"""
        return self.embedding_cache.get(content)
    
    def _calculate_similarity(self, vec1: List[float], vec2: List[float]) -> float:
        """
        è®¡ç®—ä¸¤ä¸ªå‘é‡ä¹‹é—´çš„ä½™å¼¦ç›¸ä¼¼æ€§
        
        Args:
            vec1: ç¬¬ä¸€ä¸ªå‘é‡
            vec2: ç¬¬äºŒä¸ªå‘é‡
            
        Returns:
            ç›¸ä¼¼æ€§åˆ†æ•° (0-1ä¹‹é—´)
        """
        if not vec1 or not vec2:
            return 0.0
            
        dot_product = sum(a * b for a, b in zip(vec1, vec2))
        magnitude1 = sum(a * a for a in vec1) ** 0.5
        magnitude2 = sum(b * b for b in vec2) ** 0.5
        
        if magnitude1 == 0 or magnitude2 == 0:
            return 0.0
        
        return dot_product / (magnitude1 * magnitude2)
    
    def _generate_embedding_fallback(self, content: str) -> Optional[List[float]]:
        """
        é™çº§æ¨¡å¼ï¼šä½¿ç”¨ç®€å•å…³é”®è¯å‘é‡åŒ–
        """
        # ç®€å•çš„TF-IDFé£æ ¼å‘é‡åŒ–ï¼ˆé™çº§å®ç°ï¼‰
        import re
        from collections import Counter
        
        # ç®€å•åˆ†è¯
        words = re.findall(r'\w+', content.lower())
        word_count = Counter(words)
        
        # ä½¿ç”¨å“ˆå¸Œæ¥ç”Ÿæˆå›ºå®šé•¿åº¦çš„å‘é‡
        vector_size = 384  # ä¸ç™¾åº¦Embeddingè¾“å‡ºç»´åº¦ä¸€è‡´
        vector = [0.0] * vector_size
        
        for word, count in word_count.items():
            hash_val = hash(word) % vector_size
            vector[hash_val] += count
        
        # å½’ä¸€åŒ–
        magnitude = sum(v*v for v in vector) ** 0.5
        if magnitude > 0:
            vector = [v/magnitude for v in vector]
        
        return vector
    
    @with_fallback(lambda self, content, tags=None, metadata=None: self._add_memory_fallback(content, tags, metadata))
    def add_memory(self, content: str, tags: List[str] = None, metadata: Dict = None) -> bool:
        """
        æ·»åŠ è®°å¿†åˆ°æ•°æ®åº“
        
        Args:
            content: è®°å¿†å†…å®¹
            tags: æ ‡ç­¾åˆ—è¡¨
            metadata: å…ƒæ•°æ®
            
        Returns:
            æ˜¯å¦æ·»åŠ æˆåŠŸ
        """
        try:
            # è¾“å…¥éªŒè¯
            if not content or not isinstance(content, str):
                print("âŒ é”™è¯¯: å†…å®¹ä¸èƒ½ä¸ºç©ºä¸”å¿…é¡»æ˜¯å­—ç¬¦ä¸²")
                return False
            
            if len(content) > 10000:  # é™åˆ¶å†…å®¹é•¿åº¦
                print("âŒ é”™è¯¯: å†…å®¹è¿‡é•¿ï¼Œè¯·ä¿æŒåœ¨10000å­—ç¬¦ä»¥å†…")
                return False
                
            if tags is not None and not isinstance(tags, list):
                print("âŒ é”™è¯¯: æ ‡ç­¾å¿…é¡»æ˜¯å­—ç¬¦ä¸²åˆ—è¡¨")
                return False
                
            if metadata is not None and not isinstance(metadata, dict):
                print("âŒ é”™è¯¯: å…ƒæ•°æ®å¿…é¡»æ˜¯å­—å…¸ç±»å‹")
                return False

            # æ£€æŸ¥å†…å®¹æ˜¯å¦å·²å­˜åœ¨
            content_hash = self._get_content_hash(content)
            if self._content_exists(content_hash):
                print(f"âš ï¸  å†…å®¹å·²å­˜åœ¨ï¼Œè·³è¿‡é‡å¤æ·»åŠ : {content[:50]}...")
                return True

            # ç”Ÿæˆå‘é‡è¡¨ç¤º
            cached_embedding = self._get_from_cache(content)
            if cached_embedding:
                embedding = cached_embedding
                print("ğŸ”„ ä½¿ç”¨ç¼“å­˜çš„åµŒå…¥å‘é‡")
            else:
                if self.client:
                    embedding = self.client.get_embedding_vector(content, model="embedding-v1")
                    if not embedding:
                        print(f"âŒ æ— æ³•ä¸ºå†…å®¹ç”Ÿæˆå‘é‡ï¼Œå°è¯•é™çº§æ¨¡å¼: {content[:50]}...")
                        embedding = self._generate_embedding_fallback(content)
                        if not embedding:
                            print("âŒ é™çº§æ¨¡å¼ä¹Ÿæ— æ³•ç”Ÿæˆå‘é‡")
                            return False
                else:
                    # é™çº§æ¨¡å¼
                    embedding = self._generate_embedding_fallback(content)
                    if not embedding:
                        print("âŒ é™çº§æ¨¡å¼ä¹Ÿæ— æ³•ç”Ÿæˆå‘é‡")
                        return False
                
                # æ·»åŠ åˆ°ç¼“å­˜
                self._add_to_cache(content, embedding)
        
            # è½¬æ¢ä¸ºJSONå­—ç¬¦ä¸²
            try:
                embedding_json = json.dumps(embedding) if embedding else None
                tags_str = ",".join(tags) if tags else ""
                metadata_json = json.dumps(metadata) if metadata else "{}"
            except TypeError as e:
                print(f"âŒ æ•°æ®åºåˆ—åŒ–é”™è¯¯: {str(e)}")
                return False
        
            # æ’å…¥æ•°æ®åº“
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            try:
                cursor.execute('''
                    INSERT OR IGNORE INTO memories (content, embedding_json, tags, metadata_json, content_hash)
                    VALUES (?, ?, ?, ?, ?)
                ''', (content, embedding_json, tags_str, metadata_json, content_hash))
                
                conn.commit()
                
                if cursor.rowcount > 0:
                    print(f"âœ… å·²æ·»åŠ è®°å¿†: {content[:50]}{'...' if len(content) > 50 else ''}")
                    return True
                else:
                    print(f"âš ï¸  å†…å®¹å·²å­˜åœ¨: {content[:50]}...")
                    return True
            except sqlite3.Error as e:
                print(f"âŒ æ•°æ®åº“æ’å…¥é”™è¯¯: {str(e)}")
                print("   å¯èƒ½åŸå› : æ•°æ®åº“æƒé™ä¸è¶³ã€ç£ç›˜ç©ºé—´ä¸è¶³æˆ–æ•°æ®åº“æŸå")
                return False
            finally:
                conn.close()
                
        except Exception as e:
            print(f"âŒ æ·»åŠ è®°å¿†æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {str(e)}")
            print("   è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
            traceback.print_exc()
            return False
    
    def _add_memory_fallback(self, content: str, tags: List[str] = None, metadata: Dict = None) -> bool:
        """é™çº§æ¨¡å¼ï¼šåªå­˜å‚¨å†…å®¹ï¼Œä¸ç”Ÿæˆå‘é‡"""
        try:
            # è¾“å…¥éªŒè¯
            if not content or not isinstance(content, str):
                print("âŒ é™çº§æ¨¡å¼ - å†…å®¹ä¸èƒ½ä¸ºç©ºä¸”å¿…é¡»æ˜¯å­—ç¬¦ä¸²")
                return False
            
            if len(content) > 10000:  # é™åˆ¶å†…å®¹é•¿åº¦
                print("âŒ é™çº§æ¨¡å¼ - å†…å®¹è¿‡é•¿ï¼Œè¯·ä¿æŒåœ¨10000å­—ç¬¦ä»¥å†…")
                return False

            # æ£€æŸ¥å†…å®¹æ˜¯å¦å·²å­˜åœ¨
            content_hash = self._get_content_hash(content)
            if self._content_exists(content_hash):
                print(f"âš ï¸  é™çº§æ¨¡å¼ - å†…å®¹å·²å­˜åœ¨ï¼Œè·³è¿‡é‡å¤æ·»åŠ : {content[:50]}...")
                return True

            # ä¸ç”Ÿæˆå‘é‡ï¼Œåªå­˜å‚¨å†…å®¹
            try:
                tags_str = ",".join(tags) if tags else ""
                metadata_json = json.dumps(metadata) if metadata else "{}"
            except TypeError as e:
                print(f"âŒ é™çº§æ¨¡å¼ - æ•°æ®åºåŒ–é”™è¯¯: {str(e)}")
                return False
        
            # æ’å…¥æ•°æ®åº“ï¼ˆembedding_jsonä¸ºNULLï¼‰
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            try:
                cursor.execute('''
                    INSERT OR IGNORE INTO memories (content, embedding_json, tags, metadata_json, content_hash)
                    VALUES (?, NULL, ?, ?, ?)
                ''', (content, tags_str, metadata_json, content_hash))
                
                conn.commit()
                
                if cursor.rowcount > 0:
                    print(f"âœ… é™çº§æ¨¡å¼ - å·²æ·»åŠ è®°å¿†: {content[:50]}{'...' if len(content) > 50 else ''}")
                    return True
                else:
                    print(f"âš ï¸  é™çº§æ¨¡å¼ - å†…å®¹å·²å­˜åœ¨: {content[:50]}...")
                    return True
            except sqlite3.Error as e:
                print(f"âŒ é™çº§æ¨¡å¼ - æ•°æ®åº“æ’å…¥é”™è¯¯: {str(e)}")
                return False
            finally:
                conn.close()
                
        except Exception as e:
            print(f"âŒ é™çº§æ¨¡å¼ - æ·»åŠ è®°å¿†æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {str(e)}")
            return False
    
    def _content_exists(self, content_hash: str) -> bool:
        """æ£€æŸ¥å†…å®¹æ˜¯å¦å·²å­˜åœ¨"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute('SELECT 1 FROM memories WHERE content_hash = ?', (content_hash,))
            exists = cursor.fetchone() is not None
            
            conn.close()
            return exists
        except:
            return False
    
    @with_fallback(lambda self, query, limit=5, tags=None: self._search_memories_fallback(query, limit, tags))
    def search_memories(self, query: str, limit: int = 5, tags: List[str] = None) -> List[Dict]:
        """
        é€šè¿‡è¯­ä¹‰æœç´¢ç›¸å…³è®°å¿†
        
        Args:
            query: æœç´¢æŸ¥è¯¢
            limit: è¿”å›ç»“æœæ•°é‡é™åˆ¶
            tags: æ ‡ç­¾è¿‡æ»¤æ¡ä»¶
            
        Returns:
            ç›¸å…³è®°å¿†åˆ—è¡¨
        """
        try:
            # è¾“å…¥éªŒè¯
            if not query or not isinstance(query, str):
                print("âŒ é”™è¯¯: æŸ¥è¯¢ä¸èƒ½ä¸ºç©ºä¸”å¿…é¡»æ˜¯å­—ç¬¦ä¸²")
                return []
                
            if limit <= 0 or limit > 100:
                print("âŒ é”™è¯¯: ç»“æœæ•°é‡é™åˆ¶å¿…é¡»åœ¨1-100ä¹‹é—´")
                return []
                
            if tags is not None and not isinstance(tags, list):
                print("âŒ é”™è¯¯: æ ‡ç­¾å¿…é¡»æ˜¯å­—ç¬¦ä¸²åˆ—è¡¨")
                return []

            # ç”ŸæˆæŸ¥è¯¢å‘é‡
            query_embedding = self._get_from_cache(query)
            if not query_embedding:
                if self.client:
                    query_embedding = self.client.get_embedding_vector(query, model="embedding-v1")
                    if query_embedding:
                        self._add_to_cache(query, query_embedding)
                else:
                    # é™çº§æ¨¡å¼
                    query_embedding = self._generate_embedding_fallback(query)
                
                if not query_embedding:
                    print("âŒ æ— æ³•ä¸ºæŸ¥è¯¢ç”Ÿæˆå‘é‡ï¼Œä½¿ç”¨å…³é”®è¯åŒ¹é…")
                    return self._keyword_search(query, limit, tags)

            # ä»æ•°æ®åº“è·å–æ‰€æœ‰æœ‰å‘é‡çš„è®°å¿†
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            try:
                # æ„å»ºæŸ¥è¯¢æ¡ä»¶
                where_clause = "WHERE embedding_json IS NOT NULL"  # åªæœç´¢æœ‰å‘é‡çš„è®°å¿†
                params = []
                
                if tags:
                    # ä¸ºæ¯ä¸ªæ ‡ç­¾æ„å»ºORæ¡ä»¶
                    tag_conditions = []
                    for tag in tags:
                        tag_conditions.extend(["tags LIKE ?", "tags LIKE ?", "tags LIKE ?"])
                        params.extend([f'%{tag}%', f'{tag},%', f'%,{tag}%'])
                    
                    if tag_conditions:
                        where_clause += f" AND ({' OR '.join(tag_conditions)})"
                
                cursor.execute(f'''
                    SELECT id, content, embedding_json, timestamp, tags, metadata_json
                    FROM memories
                    {where_clause}
                    ORDER BY timestamp DESC
                ''', params)
                
                rows = cursor.fetchall()
            except sqlite3.Error as e:
                print(f"âŒ æ•°æ®åº“æŸ¥è¯¢é”™è¯¯: {str(e)}")
                print("   å¯èƒ½åŸå› : æ•°æ®åº“æŸåã€æƒé™é—®é¢˜æˆ–SQLè¯­æ³•é”™è¯¯")
                return []
            finally:
                conn.close()
            
            # è®¡ç®—ä¸æŸ¥è¯¢å‘é‡çš„ç›¸ä¼¼æ€§
            results = []
            for row in rows:
                try:
                    embedding = json.loads(row[2])  # embedding_json
                    similarity = self._calculate_similarity(query_embedding, embedding)
                    
                    results.append({
                        "id": row[0],
                        "content": row[1],
                        "similarity": similarity,
                        "timestamp": row[3],
                        "tags": row[4],
                        "metadata": json.loads(row[5]) if row[5] else {},
                    })
                except json.JSONDecodeError:
                    print(f"âš ï¸ è­¦å‘Š: æ— æ³•è§£æè®°å¿†ID {row[0]} çš„åµŒå…¥å‘é‡ï¼Œè·³è¿‡è¯¥è®°å½•")
                    continue
                except Exception as e:
                    print(f"âš ï¸ è­¦å‘Š: å¤„ç†è®°å¿†ID {row[0]} æ—¶å‡ºé”™: {str(e)}ï¼Œè·³è¿‡è¯¥è®°å½•")
                    continue
            
            # æŒ‰ç›¸ä¼¼æ€§æ’åºå¹¶è¿”å›å‰Nä¸ªç»“æœ
            results.sort(key=lambda x: x["similarity"], reverse=True)
            return results[:limit]
            
        except Exception as e:
            print(f"âŒ æœç´¢è®°å¿†æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {str(e)}")
            print("   è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
            traceback.print_exc()
            return []
    
    def _search_memories_fallback(self, query: str, limit: int = 5, tags: List[str] = None) -> List[Dict]:
        """é™çº§æ¨¡å¼ï¼šä½¿ç”¨å…³é”®è¯åŒ¹é…æœç´¢"""
        return self._keyword_search(query, limit, tags)
    
    def _keyword_search(self, query: str, limit: int = 5, tags: List[str] = None) -> List[Dict]:
        """å…³é”®è¯åŒ¹é…æœç´¢ï¼ˆç”¨äºé™çº§æ¨¡å¼ï¼‰"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # æ„å»ºæŸ¥è¯¢æ¡ä»¶
            where_clause = "WHERE 1=1"
            params = []
            
            if tags:
                # ä¸ºæ¯ä¸ªæ ‡ç­¾æ„å»ºORæ¡ä»¶
                tag_conditions = []
                for tag in tags:
                    tag_conditions.extend(["tags LIKE ?", "tags LIKE ?", "tags LIKE ?"])
                    params.extend([f'%{tag}%', f'{tag},%', f'%,{tag}%'])
                
                if tag_conditions:
                    where_clause += f" AND ({' OR '.join(tag_conditions)})"
            
            cursor.execute(f'''
                SELECT id, content, timestamp, tags, metadata_json
                FROM memories
                {where_clause}
                ORDER BY timestamp DESC
            ''', params)
            
            rows = cursor.fetchall()
            conn.close()
            
            # ä½¿ç”¨å…³é”®è¯åŒ¹é…è®¡ç®—ç›¸ä¼¼æ€§
            query_lower = query.lower()
            results = []
            
            for row in rows:
                content_lower = row[1].lower()
                # ç®€å•çš„å…³é”®è¯åŒ¹é…å¾—åˆ†
                score = 0
                for word in query_lower.split():
                    if word in content_lower:
                        score += 1
                
                if score > 0:  # åªè¿”å›åŒ¹é…çš„
                    results.append({
                        "id": row[0],
                        "content": row[1],
                        "similarity": score / (len(query_lower.split()) + 1),  # å½’ä¸€åŒ–å¾—åˆ†
                        "timestamp": row[2],
                        "tags": row[3],
                        "metadata": json.loads(row[4]) if row[4] else {},
                    })
            
            # æŒ‰åŒ¹é…åº¦æ’åº
            results.sort(key=lambda x: x["similarity"], reverse=True)
            return results[:limit]
            
        except Exception as e:
            print(f"âŒ å…³é”®è¯æœç´¢æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            return []
    
    def get_all_memories(self) -> List[Dict]:
        """
        è·å–æ‰€æœ‰è®°å¿†ï¼ˆä¸åˆ†é¡µï¼‰
        
        Returns:
            æ‰€æœ‰è®°å¿†åˆ—è¡¨
        """
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute('''
                SELECT id, content, embedding_json, timestamp, tags, metadata_json
                FROM memories
                ORDER BY timestamp DESC
            ''')
            
            rows = cursor.fetchall()
            conn.close()
            
            results = []
            for row in rows:
                try:
                    results.append({
                        "id": row[0],
                        "content": row[1],
                        "has_embedding": row[2] is not None,  # ä»…è¿”å›æ˜¯å¦æœ‰åµŒå…¥ï¼Œä¸è¿”å›å®é™…å‘é‡
                        "timestamp": row[3],
                        "tags": row[4],
                        "metadata": json.loads(row[5]) if row[5] else {},
                    })
                except json.JSONDecodeError:
                    print(f"âš ï¸ è­¦å‘Š: æ— æ³•è§£æè®°å¿†ID {row[0]} çš„å…ƒæ•°æ®ï¼Œä½¿ç”¨ç©ºå­—å…¸")
                    results.append({
                        "id": row[0],
                        "content": row[1],
                        "has_embedding": row[2] is not None,
                        "timestamp": row[3],
                        "tags": row[4],
                        "metadata": {},
                    })
                except Exception as e:
                    print(f"âš ï¸ è­¦å‘Š: å¤„ç†è®°å¿†ID {row[0]} æ—¶å‡ºé”™: {str(e)}ï¼Œè·³è¿‡è¯¥è®°å½•")
                    continue
            
            return results
            
        except sqlite3.Error as e:
            print(f"âŒ è·å–æ‰€æœ‰è®°å¿†æ—¶æ•°æ®åº“é”™è¯¯: {str(e)}")
            print("   å¯èƒ½åŸå› : æ•°æ®åº“æŸåã€æƒé™é—®é¢˜æˆ–è¿æ¥å¤±è´¥")
            return []
        except Exception as e:
            print(f"âŒ è·å–æ‰€æœ‰è®°å¿†æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {str(e)}")
            print("   è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
            traceback.print_exc()
            return []
    
    def get_statistics(self) -> Dict:
        """
        è·å–æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # æ€»è®°å¿†æ•°
            cursor.execute('SELECT COUNT(*) FROM memories')
            total_memories = cursor.fetchone()[0]
            
            # æœ‰åµŒå…¥çš„è®°å¿†æ•°
            cursor.execute('SELECT COUNT(*) FROM memories WHERE embedding_json IS NOT NULL')
            memories_with_embeddings = cursor.fetchone()[0]
            
            # æŒ‰æ ‡ç­¾åˆ†ç»„ç»Ÿè®¡
            cursor.execute('SELECT tags, COUNT(*) FROM memories GROUP BY tags')
            tag_rows = cursor.fetchall()
            tag_counts = dict(tag_rows) if tag_rows else {}
            
            # æœ€æ—©å’Œæœ€æ–°çš„è®°å¿†æ—¶é—´
            cursor.execute('SELECT MIN(timestamp), MAX(timestamp) FROM memories')
            min_max_result = cursor.fetchone()
            min_time, max_time = min_max_result if min_max_result else (None, None)
            
            conn.close()
            
            return {
                "total_memories": total_memories,
                "memories_with_embeddings": memories_with_embeddings,
                "memories_without_embeddings": total_memories - memories_with_embeddings,
                "tag_distribution": tag_counts,
                "earliest_memory": min_time,
                "latest_memory": max_time,
                "fallback_mode": self.fallback_mode
            }
            
        except sqlite3.Error as e:
            print(f"âŒ è·å–ç»Ÿè®¡æ•°æ®æ—¶æ•°æ®åº“é”™è¯¯: {str(e)}")
            print("   å¯èƒ½åŸå› : æ•°æ®åº“æŸåã€æƒé™é—®é¢˜æˆ–è¿æ¥å¤±è´¥")
            return {
                "total_memories": 0,
                "memories_with_embeddings": 0,
                "memories_without_embeddings": 0,
                "tag_distribution": {},
                "earliest_memory": None,
                "latest_memory": None,
                "fallback_mode": True
            }
        except Exception as e:
            print(f"âŒ è·å–ç»Ÿè®¡æ•°æ®æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {str(e)}")
            print("   è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
            traceback.print_exc()
            return {
                "total_memories": 0,
                "memories_with_embeddings": 0,
                "memories_without_embeddings": 0,
                "tag_distribution": {},
                "earliest_memory": None,
                "latest_memory": None,
                "fallback_mode": True
            }


def main():
    """
    ä¸»å‡½æ•° - æ¼”ç¤ºå¢å¼ºç‰ˆç™¾åº¦Embeddingå†…å­˜æ•°æ®åº“åŠŸèƒ½
    """
    print("ğŸ¤– å¢å¼ºç‰ˆç™¾åº¦Embeddingå†…å­˜æ•°æ®åº“")
    print("="*60)
    
    try:
        # åˆ›å»ºå†…å­˜æ•°æ®åº“å®ä¾‹
        mem_db = EnhancedMemoryBaiduEmbeddingDB()
        
        print("\nğŸ“Š æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯:")
        stats = mem_db.get_statistics()
        print(f"  æ€»è®°å¿†æ•°: {stats['total_memories']}")
        print(f"  æœ‰åµŒå…¥çš„è®°å¿†æ•°: {stats['memories_with_embeddings']}")
        print(f"  æ— åµŒå…¥çš„è®°å¿†æ•°: {stats['memories_without_embeddings']}")
        print(f"  é™çº§æ¨¡å¼: {'æ˜¯' if stats['fallback_mode'] else 'å¦'}")
        print(f"  æ ‡ç­¾åˆ†å¸ƒ: {dict(list(stats['tag_distribution'].items())[:5])}")  # åªæ˜¾ç¤ºå‰5ä¸ª
        print(f"  æœ€æ—©è®°å¿†: {stats['earliest_memory']}")
        print(f"  æœ€æ–°è®°å¿†: {stats['latest_memory']}")
        
        print("\nğŸ“ æ·»åŠ è®°å¿†ç¤ºä¾‹:")
        # æ·»åŠ ä¸€äº›ç¤ºä¾‹è®°å¿†
        examples = [
            {
                "content": "ç”¨æˆ·å–œæ¬¢å¥èº«ï¼Œç‰¹åˆ«å…³æ³¨èƒ¸è‚Œå’ŒèƒŒè‚Œè®­ç»ƒï¼Œä¸å–œæ¬¢ç»ƒæ–œæ–¹è‚Œ",
                "tags": ["user-preference", "fitness"],
                "metadata": {"user": "ä¹å", "date": "2026-01-30"}
            },
            {
                "content": "ä»Šå¤©çš„å¤©æ°”å¾ˆå¥½ï¼Œé€‚åˆæˆ·å¤–è¿åŠ¨",
                "tags": ["weather", "activity"],
                "metadata": {"date": "2026-01-30"}
            },
            {
                "content": "ç”¨æˆ·çš„ç›®æ ‡æ˜¯è¯»ä¹¦500æœ¬ã€è§‚å½±2000éƒ¨ã€åˆ›ä½œ20é¦–æ­Œã€å‚¨è“„50ä¸‡ã€å­¦ä¸€é—¨å¤–è¯­",
                "tags": ["user-goal", "long-term"],
                "metadata": {"user": "ä¹å", "priority": "high"}
            }
        ]
        
        for example in examples:
            success = mem_db.add_memory(
                example["content"],
                example["tags"],
                example["metadata"]
            )
            print(f"  æ·»åŠ è®°å¿†: {'âœ…' if success else 'âŒ'} - {example['content'][:30]}...")
        
        print("\nğŸ” è¯­ä¹‰æœç´¢ç¤ºä¾‹:")
        # æœç´¢ç›¸å…³è®°å¿†
        search_queries = [
            "ç”¨æˆ·å¥èº«åå¥½",
            "è¯»ä¹¦å’Œå­¦ä¹ ç›®æ ‡",
            "ä»Šå¤©çš„æ´»åŠ¨å»ºè®®"
        ]
        
        for query in search_queries:
            print(f"\n  æœç´¢: '{query}'")
            results = mem_db.search_memories(query, limit=2)
            if results:
                for i, result in enumerate(results, 1):
                    print(f"    {i}. ç›¸ä¼¼åº¦: {result['similarity']:.3f} - {result['content'][:50]}...")
            else:
                print("    æœªæ‰¾åˆ°ç›¸å…³è®°å¿†")
        
        print(f"\nğŸ‰ å¢å¼ºç‰ˆç™¾åº¦Embeddingå†…å­˜æ•°æ®åº“æ¼”ç¤ºå®Œæˆï¼")
        print(f"  å·¥ä½œæ¨¡å¼: {'å®Œæ•´åŠŸèƒ½' if not stats['fallback_mode'] else 'é™çº§æ¨¡å¼'}")
        print("å·²æˆåŠŸå®ç°åŸºäºå‘é‡ç›¸ä¼¼æ€§çš„æ™ºèƒ½è®°å¿†ç®¡ç†åŠŸèƒ½")
        
    except Exception as e:
        print(f"\nâŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        print("   è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
        traceback.print_exc()
        return 1
    
    return 0


if __name__ == "__main__":
    main()
